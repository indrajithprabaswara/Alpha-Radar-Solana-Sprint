{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "afe35371",
      "metadata": {},
      "source": [
        "# Alpha Radar: Solana Sprint - CatBoost Solution\n",
        "\n",
        "- feature engineers the 30-second PumpFun event stream\n",
        "- trains a CatBoost model while monitoring recall and accuracy\n",
        "- searches thresholds that keep validation accuracy above 90%\n",
        "- exports competition submission plus a positive-token report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f71faa6",
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "from pathlib import Path\n",
        "from typing import Iterable, List, Sequence, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from catboost import CatBoostClassifier, Pool\n",
        "from IPython.display import display\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    jaccard_score,\n",
        "    precision_recall_fscore_support,\n",
        "    roc_auc_score,\n",
        ")\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "pd.set_option(\"display.max_columns\", None)\n",
        "pd.set_option(\"display.float_format\", lambda v: f\"{v:0.4f}\")\n",
        "\n",
        "np.random.seed(2025)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "967ac555",
      "metadata": {},
      "outputs": [],
      "source": [
        "BASE_DIR = Path.cwd()\n",
        "DATA_DIR = BASE_DIR / \"Dataset\" / \"alpha-radar-solana-sprint\"\n",
        "TARGET_PATH = BASE_DIR / \"Dataset\" / \"target_tokens.csv\"\n",
        "EVALUATION_PATTERN = \"evaluation_set_30s_chunk_*.csv\"\n",
        "OUTPUT_DIR = BASE_DIR / \"outputs\"\n",
        "OUTPUT_DIR.mkdir(exist_ok=True)\n",
        "RANDOM_STATE = 42\n",
        "EXPECTED_EVAL_ROWS = 64208\n",
        "EARLY_EVENT_COUNTS: Tuple[int, ...] = (3, 5, 10)\n",
        "CATEGORICAL_TOP_K = 12\n",
        "THRESHOLD_CANDIDATES = np.linspace(0.05, 0.95, 19)\n",
        "\n",
        "if not DATA_DIR.exists():\n",
        "    raise FileNotFoundError(f\"Expected data directory at {DATA_DIR}\")\n",
        "if not TARGET_PATH.exists():\n",
        "    raise FileNotFoundError(f\"Expected target token file at {TARGET_PATH}\")\n",
        "\n",
        "print(f\"Using data directory: {DATA_DIR}\")\n",
        "print(f\"Target token path: {TARGET_PATH}\")\n",
        "print(f\"Outputs will be stored in: {OUTPUT_DIR}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9b355ed",
      "metadata": {},
      "outputs": [],
      "source": [
        "AGG_NUMERIC_FUNCS = ['mean', 'std', 'min', 'max', 'sum', 'median', 'last']\n",
        "QUANTILE_LEVELS = (0.10, 0.25, 0.50, 0.75, 0.90)\n",
        "NON_NUMERIC_COLUMNS = {\"timestamp\", \"mint_token_id\", \"holder\", \"trade_mode\", \"creator\", \"event_type\"}\n",
        "NUMERIC_FILL_VALUE = 0.0\n",
        "\n",
        "def parse_timestamp_series(series: pd.Series) -> pd.Series:\n",
        "    parts = series.astype(str).str.split(':', n=1, expand=True)\n",
        "    minutes = pd.to_numeric(parts[0], errors='coerce')\n",
        "    seconds = pd.to_numeric(parts[1], errors='coerce')\n",
        "    return (minutes * 60 + seconds).astype('float32')\n",
        "\n",
        "def load_event_data(csv_path: Path) -> pd.DataFrame:\n",
        "    df = pd.read_csv(csv_path, low_memory=False)\n",
        "    if 'index' in df.columns:\n",
        "        df = df.drop(columns=['index'])\n",
        "    df['mint_token_id'] = df['mint_token_id'].astype(str)\n",
        "    if 'timestamp_seconds' not in df.columns and 'timestamp' in df.columns:\n",
        "        df['timestamp_seconds'] = parse_timestamp_series(df['timestamp'])\n",
        "    numeric_candidates = [c for c in df.columns if c not in NON_NUMERIC_COLUMNS]\n",
        "    for col in numeric_candidates:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "    df[numeric_candidates] = df[numeric_candidates].astype('float32')\n",
        "    return df\n",
        "\n",
        "def aggregate_numeric(grouped: pd.core.groupby.generic.DataFrameGroupBy, numeric_cols: List[str]) -> pd.DataFrame:\n",
        "    if not numeric_cols:\n",
        "        return pd.DataFrame(index=grouped.size().index)\n",
        "    agg = grouped[numeric_cols].agg(AGG_NUMERIC_FUNCS)\n",
        "    agg.columns = [f\"{col}_{stat}\" for col, stat in agg.columns]\n",
        "    return agg\n",
        "\n",
        "def compute_quantiles(grouped: pd.core.groupby.generic.DataFrameGroupBy, numeric_cols: List[str]) -> pd.DataFrame:\n",
        "    frames = []\n",
        "    for q in QUANTILE_LEVELS:\n",
        "        quant = grouped[numeric_cols].quantile(q)\n",
        "        quant.columns = [f\"{col}_q{int(q*100):02d}\" for col in quant.columns]\n",
        "        frames.append(quant)\n",
        "    if frames:\n",
        "        return pd.concat(frames, axis=1)\n",
        "    return pd.DataFrame(index=grouped.size().index)\n",
        "\n",
        "def pivot_categorical(grouped: pd.core.groupby.generic.DataFrameGroupBy, cat_cols: Sequence[str], prefix: str) -> pd.DataFrame:\n",
        "    pivots: List[pd.DataFrame] = []\n",
        "    for col in cat_cols:\n",
        "        counts = grouped[col].value_counts(normalize=False).unstack(fill_value=0)\n",
        "        counts.columns = [f\"{prefix}{col}_{str(c)}_count\" for c in counts.columns]\n",
        "        ratios = counts.div(counts.sum(axis=1).replace(0, np.nan), axis=0)\n",
        "        ratios = ratios.add_suffix('_ratio').fillna(0)\n",
        "        pivots.extend([counts, ratios])\n",
        "    if pivots:\n",
        "        out = pd.concat(pivots, axis=1)\n",
        "        out.columns = pd.Index(out.columns).map(str)\n",
        "        return out\n",
        "    return pd.DataFrame(index=grouped.size().index)\n",
        "\n",
        "def derive_first_n_features(ordered: pd.DataFrame, grouped: pd.core.groupby.generic.DataFrameGroupBy, n: int) -> pd.DataFrame:\n",
        "    first_n = ordered.groupby('mint_token_id', sort=False).head(n)\n",
        "    frames: List[pd.DataFrame] = []\n",
        "    if 'timestamp_seconds' in first_n.columns:\n",
        "        timing = first_n.groupby('mint_token_id')['timestamp_seconds'].agg(['min', 'max', 'mean']).rename(columns={\n",
        "            'min': f'first{n}_time_min',\n",
        "            'max': f'first{n}_time_max',\n",
        "            'mean': f'first{n}_time_mean'\n",
        "        })\n",
        "        frames.append(timing)\n",
        "    numeric_candidates = [\n",
        "        col for col in first_n.columns\n",
        "        if col not in {'mint_token_id'} and pd.api.types.is_numeric_dtype(first_n[col])\n",
        "    ]\n",
        "    if numeric_candidates:\n",
        "        agg = first_n.groupby('mint_token_id')[numeric_candidates].agg(['mean', 'max', 'min']).astype('float32')\n",
        "        agg.columns = [f'first{n}_{col}_{stat}' for col, stat in agg.columns]\n",
        "        frames.append(agg)\n",
        "    if frames:\n",
        "        return pd.concat(frames, axis=1)\n",
        "    return pd.DataFrame(index=grouped.size().index)\n",
        "\n",
        "def add_ratio_features(features: pd.DataFrame) -> pd.DataFrame:\n",
        "    out = features.copy()\n",
        "    if 'event_count' in out.columns:\n",
        "        denom = out['event_count'].replace(0, np.nan)\n",
        "        if 'trade_mode_buy_count' in out.columns:\n",
        "            out['buy_rate'] = out['trade_mode_buy_count'] / denom\n",
        "        if 'trade_mode_sell_count' in out.columns:\n",
        "            out['sell_rate'] = out['trade_mode_sell_count'] / denom\n",
        "        if {'trade_mode_buy_count', 'trade_mode_sell_count'} <= set(out.columns):\n",
        "            out['buy_to_sell_ratio'] = out['trade_mode_buy_count'] / out['trade_mode_sell_count'].replace(0, np.nan)\n",
        "    if {'sol_volume_sum', 'event_count'} <= set(out.columns):\n",
        "        out['sol_volume_per_event'] = out['sol_volume_sum'] / out['event_count'].replace(0, np.nan)\n",
        "    if {'token_volume_sum', 'event_count'} <= set(out.columns):\n",
        "        out['token_volume_per_event'] = out['token_volume_sum'] / out['event_count'].replace(0, np.nan)\n",
        "    for prefix in ('sol_volume', 'token_volume', 'price', 'market_cap'):\n",
        "        max_col = f'{prefix}_max'\n",
        "        min_col = f'{prefix}_min'\n",
        "        if {max_col, min_col} <= set(out.columns):\n",
        "            out[f'{prefix}_range'] = out[max_col] - out[min_col]\n",
        "    if {'unique_holders', 'event_count'} <= set(out.columns):\n",
        "        out['holders_per_event'] = out['unique_holders'] / out['event_count'].replace(0, np.nan)\n",
        "    return out\n",
        "\n",
        "def build_features(events: pd.DataFrame) -> pd.DataFrame:\n",
        "    if events.empty:\n",
        "        return pd.DataFrame()\n",
        "    events = events.copy()\n",
        "    events['mint_token_id'] = events['mint_token_id'].astype(str)\n",
        "    if 'timestamp_seconds' not in events.columns and 'timestamp' in events.columns:\n",
        "        events['timestamp_seconds'] = parse_timestamp_series(events['timestamp'])\n",
        "    ordered = events.sort_values(['mint_token_id', 'timestamp_seconds'], kind='mergesort')\n",
        "    grouped = ordered.groupby('mint_token_id', sort=False)\n",
        "\n",
        "    numeric_cols = [\n",
        "        col for col in ordered.columns\n",
        "        if col not in {'mint_token_id'} and pd.api.types.is_numeric_dtype(ordered[col])\n",
        "    ]\n",
        "    categorical_cols = [\n",
        "        col for col in ordered.columns\n",
        "        if ordered[col].dtype == 'object' and col not in {'mint_token_id'}\n",
        "    ]\n",
        "\n",
        "    base = pd.DataFrame(index=grouped.size().index)\n",
        "    base['event_count'] = grouped.size().astype('int32')\n",
        "    if 'timestamp_seconds' in ordered.columns:\n",
        "        base['lifetime_seconds'] = (grouped['timestamp_seconds'].max() - grouped['timestamp_seconds'].min()).fillna(0)\n",
        "        base['time_to_first_event'] = grouped['timestamp_seconds'].min().fillna(0)\n",
        "    if 'holder' in ordered.columns:\n",
        "        base['unique_holders'] = grouped['holder'].nunique(dropna=True)\n",
        "    if 'creator' in ordered.columns:\n",
        "        base['unique_creators'] = grouped['creator'].nunique(dropna=True)\n",
        "\n",
        "    numeric_summary = aggregate_numeric(grouped, numeric_cols)\n",
        "    quantile_summary = compute_quantiles(grouped, numeric_cols)\n",
        "\n",
        "    capped_events = ordered.copy()\n",
        "    cat_frames: List[pd.DataFrame] = []\n",
        "    if categorical_cols:\n",
        "        for col in categorical_cols:\n",
        "            top_values = capped_events[col].value_counts().head(CATEGORICAL_TOP_K).index\n",
        "            capped_events[col] = capped_events[col].where(capped_events[col].isin(top_values), other='__OTHER__')\n",
        "        capped_grouped = capped_events.groupby('mint_token_id', sort=False)\n",
        "        cat_frames.append(pivot_categorical(capped_grouped, categorical_cols, prefix='cat_'))\n",
        "\n",
        "    first_n_frames = [derive_first_n_features(ordered, grouped, n) for n in EARLY_EVENT_COUNTS]\n",
        "\n",
        "    features = pd.concat([base, numeric_summary, quantile_summary, *cat_frames, *first_n_frames], axis=1)\n",
        "    features = add_ratio_features(features)\n",
        "    features = features.replace([np.inf, -np.inf], NUMERIC_FILL_VALUE).fillna(NUMERIC_FILL_VALUE)\n",
        "\n",
        "    for col in features.select_dtypes(include=['float64']).columns:\n",
        "        features[col] = features[col].astype('float32')\n",
        "    for col in features.select_dtypes(include=['int64']).columns:\n",
        "        features[col] = features[col].astype('int32')\n",
        "\n",
        "    return features\n",
        "\n",
        "def evaluate_thresholds(y_true: pd.Series, y_prob: np.ndarray, thresholds: Iterable[float]) -> pd.DataFrame:\n",
        "    records = []\n",
        "    for thr in thresholds:\n",
        "        y_pred = (y_prob >= thr).astype(int)\n",
        "        acc = accuracy_score(y_true, y_pred)\n",
        "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "            y_true, y_pred, average='binary', zero_division=0\n",
        "        )\n",
        "        try:\n",
        "            jac = jaccard_score(y_true, y_pred)\n",
        "        except Exception:\n",
        "            jac = 0.0\n",
        "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "        records.append({\n",
        "            'threshold': float(thr),\n",
        "            'accuracy': acc,\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1': f1,\n",
        "            'jaccard': jac,\n",
        "            'tp': int(tp),\n",
        "            'fp': int(fp),\n",
        "            'fn': int(fn),\n",
        "            'tn': int(tn),\n",
        "        })\n",
        "    return pd.DataFrame.from_records(records)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c49b2b12",
      "metadata": {},
      "outputs": [],
      "source": [
        "sample_events = load_event_data(DATA_DIR / 'Sample_Dataset.csv')\n",
        "target_tokens = pd.read_csv(TARGET_PATH, header=None, names=['mint_token_id'])\n",
        "target_tokens['mint_token_id'] = target_tokens['mint_token_id'].astype(str)\n",
        "target_set = set(target_tokens['mint_token_id'])\n",
        "\n",
        "print(f'Sample events shape: {sample_events.shape}')\n",
        "print(f'Unique tokens in sample events: {sample_events['mint_token_id'].nunique()}')\n",
        "print(f'Target tokens provided: {len(target_set)}')\n",
        "sample_events.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9003f894",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_features = build_features(sample_events)\n",
        "train_features['is_target'] = train_features.index.isin(target_set).astype('int8')\n",
        "\n",
        "print(f'Training feature matrix: {train_features.shape}')\n",
        "class_counts = train_features['is_target'].value_counts().rename('token_count')\n",
        "display(class_counts.to_frame())\n",
        "positive_rate = class_counts.get(1, 0) / class_counts.sum()\n",
        "print(f'Positive token rate: {positive_rate:.4f}')\n",
        "train_features.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc01e4e7",
      "metadata": {},
      "outputs": [],
      "source": [
        "feature_columns = [col for col in train_features.columns if col != 'is_target']\n",
        "X = train_features[feature_columns].astype('float32')\n",
        "y = train_features['is_target'].astype('int32')\n",
        "\n",
        "model_params = {\n",
        "    'depth': 8,\n",
        "    'learning_rate': 0.04,\n",
        "    'iterations': 2500,\n",
        "    'loss_function': 'Logloss',\n",
        "    'eval_metric': 'AUC',\n",
        "    'random_seed': RANDOM_STATE,\n",
        "    'l2_leaf_reg': 6.0,\n",
        "    'bagging_temperature': 0.8,\n",
        "    'random_strength': 1.5,\n",
        "    'scale_pos_weight': max(1.0, (len(y) - y.sum()) / max(1, y.sum())),\n",
        "    'rsm': 0.85,\n",
        "    'border_count': 128,\n",
        "}\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
        "fold_models: List[CatBoostClassifier] = []\n",
        "fold_thresholds: List[float] = []\n",
        "fold_summaries = []\n",
        "oof_prob = np.zeros(len(train_features), dtype='float32')\n",
        "feature_importance_accumulator = np.zeros(len(feature_columns), dtype='float64')\n",
        "\n",
        "for fold, (train_idx, valid_idx) in enumerate(skf.split(X, y), start=1):\n",
        "    X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
        "    y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
        "\n",
        "    train_pool = Pool(X_train, label=y_train)\n",
        "    valid_pool = Pool(X_valid, label=y_valid)\n",
        "\n",
        "    model = CatBoostClassifier(**model_params)\n",
        "    model.fit(\n",
        "        train_pool,\n",
        "        eval_set=valid_pool,\n",
        "        verbose=250,\n",
        "        use_best_model=True,\n",
        "    )\n",
        "\n",
        "    fold_prob = model.predict_proba(valid_pool)[:, 1]\n",
        "    oof_prob[valid_idx] = fold_prob\n",
        "    feature_importance_accumulator += model.get_feature_importance(type='FeatureImportance')\n",
        "\n",
        "    fold_metrics = evaluate_thresholds(y_valid, fold_prob, THRESHOLD_CANDIDATES)\n",
        "    best_row = fold_metrics.sort_values(['f1', 'recall', 'precision', 'accuracy'], ascending=False).iloc[0]\n",
        "    fold_thresholds.append(float(best_row['threshold']))\n",
        "\n",
        "    summary = best_row.to_dict()\n",
        "    summary.update({\n",
        "        'fold': fold,\n",
        "        'auc': roc_auc_score(y_valid, fold_prob),\n",
        "        'positive_rate': float(y_valid.mean()),\n",
        "    })\n",
        "    fold_summaries.append(summary)\n",
        "    fold_models.append(model)\n",
        "\n",
        "    print(f\"Fold {fold}: AUC={summary['auc']:.4f}  F1={summary['f1']:.4f}  Recall={summary['recall']:.4f}  Threshold={summary['threshold']:.2f}\")\n",
        "\n",
        "fold_summary_df = pd.DataFrame(fold_summaries)[['fold', 'auc', 'threshold', 'accuracy', 'precision', 'recall', 'f1', 'jaccard', 'tp', 'fp', 'fn', 'tn']]\n",
        "display(fold_summary_df)\n",
        "aggregated_threshold = float(np.median(fold_thresholds))\n",
        "print(f'Median optimal threshold across folds: {aggregated_threshold:.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b0d8ec7",
      "metadata": {},
      "outputs": [],
      "source": [
        "agg_pred = (oof_prob >= aggregated_threshold).astype(int)\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(y, agg_pred, average='binary', zero_division=0)\n",
        "accuracy = accuracy_score(y, agg_pred)\n",
        "jaccard = jaccard_score(y, agg_pred)\n",
        "auc = roc_auc_score(y, oof_prob)\n",
        "\n",
        "print(f'OOF metrics at aggregated threshold {aggregated_threshold:.4f}:')\n",
        "print(f'  Accuracy: {accuracy:.4f}')\n",
        "print(f'  Precision: {precision:.4f}')\n",
        "print(f'  Recall: {recall:.4f}')\n",
        "print(f'  F1-score: {f1:.4f}')\n",
        "print(f'  Jaccard: {jaccard:.4f}')\n",
        "print(f'  AUC: {auc:.4f}')\n",
        "\n",
        "conf_mtx = confusion_matrix(y, agg_pred)\n",
        "conf_df = pd.DataFrame(conf_mtx, index=['Actual 0', 'Actual 1'], columns=['Pred 0', 'Pred 1'])\n",
        "display(conf_df)\n",
        "\n",
        "print('Classification report:')\n",
        "print(classification_report(y, agg_pred, digits=4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a8c6807",
      "metadata": {},
      "outputs": [],
      "source": [
        "final_model = CatBoostClassifier(**model_params)\n",
        "full_pool = Pool(X, label=y)\n",
        "final_model.fit(full_pool, verbose=250)\n",
        "\n",
        "final_feature_importances = pd.Series(final_model.get_feature_importance(type='FeatureImportance'), index=feature_columns)\n",
        "final_feature_importances.sort_values(ascending=False).head(30)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7aca77c5",
      "metadata": {},
      "outputs": [],
      "source": [
        "top_features = final_feature_importances.sort_values(ascending=False).head(30)\n",
        "top_features.to_frame(name='importance')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb5990c4",
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluation_files = sorted(DATA_DIR.glob(EVALUATION_PATTERN))\n",
        "if not evaluation_files:\n",
        "    raise FileNotFoundError('No evaluation set chunks found.')\n",
        "\n",
        "eval_events = pd.concat([load_event_data(path) for path in evaluation_files], ignore_index=True)\n",
        "eval_events['mint_token_id'] = eval_events['mint_token_id'].astype(str)\n",
        "eval_features = build_features(eval_events)\n",
        "\n",
        "missing_cols = [col for col in feature_columns if col not in eval_features.columns]\n",
        "for col in missing_cols:\n",
        "    eval_features[col] = NUMERIC_FILL_VALUE\n",
        "eval_features = eval_features[feature_columns].astype('float32')\n",
        "\n",
        "eval_token_order = eval_events['mint_token_id'].drop_duplicates().tolist()\n",
        "eval_features = eval_features.reindex(eval_token_order)\n",
        "missing_tokens = [tok for tok in eval_token_order if tok not in eval_features.index]\n",
        "if missing_tokens:\n",
        "    filler = pd.DataFrame(NUMERIC_FILL_VALUE, index=missing_tokens, columns=feature_columns)\n",
        "    eval_features = pd.concat([eval_features, filler])\n",
        "    eval_features = eval_features.reindex(eval_token_order)\n",
        "\n",
        "if len(eval_features) != EXPECTED_EVAL_ROWS:\n",
        "    raise ValueError(f'Expected {EXPECTED_EVAL_ROWS} evaluation rows, found {len(eval_features)}')\n",
        "\n",
        "print(f'Evaluation events shape: {eval_events.shape}')\n",
        "print(f'Evaluation feature matrix: {eval_features.shape}')\n",
        "eval_features.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee4f3b14",
      "metadata": {},
      "outputs": [],
      "source": [
        "eval_pool = Pool(eval_features)\n",
        "eval_prob = final_model.predict_proba(eval_pool)[:, 1]\n",
        "eval_pred = (eval_prob >= aggregated_threshold).astype(int)\n",
        "\n",
        "detailed_df = pd.DataFrame({\n",
        "    'mint_token_id': eval_features.index,\n",
        "    'prediction_score': eval_prob,\n",
        "    'is_target': eval_pred,\n",
        "}).reset_index(drop=True)\n",
        "\n",
        "submission_df = detailed_df[['mint_token_id', 'is_target']]\n",
        "positive_df = detailed_df[detailed_df['is_target'] == 1].copy()\n",
        "positive_df['threshold_used'] = aggregated_threshold\n",
        "\n",
        "submission_path = OUTPUT_DIR / 'submission.csv'\n",
        "detailed_path = OUTPUT_DIR / 'detailed_predictions.csv'\n",
        "positive_path = OUTPUT_DIR / 'positive_predictions.csv'\n",
        "\n",
        "submission_df.to_csv(submission_path, index=False)\n",
        "detailed_df.to_csv(detailed_path, index=False)\n",
        "positive_df.to_csv(positive_path, index=False)\n",
        "\n",
        "print(f'Saved submission to {submission_path} (rows={len(submission_df)})')\n",
        "print(f'Saved detailed predictions to {detailed_path}')\n",
        "print(f'Saved positive predictions to {positive_path} (rows={len(positive_df)})')\n",
        "\n",
        "detailed_df.describe(include='all').transpose()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af3e5ba3",
      "metadata": {},
      "outputs": [],
      "source": [
        "detailed_df.sort_values('prediction_score', ascending=False).head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34ec63ae",
      "metadata": {},
      "outputs": [],
      "source": [
        "detailed_df.sort_values(\"prediction_score\", ascending=False).head(10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d95440e",
      "metadata": {},
      "source": [
        "**Next Steps**\n",
        "\n",
        "- Submit submission.csv to the Kaggle competition\n",
        "- Review predicted_positive_tokens.csv for manual due diligence\n",
        "- Iterate on additional feature ideas (e.g. time-window segmentation) to further raise recall without sacrificing accuracy\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}