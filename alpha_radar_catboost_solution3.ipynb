{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alpha Radar CatBoost Solution v3\n",
    "\n",
    "Robust feature engineering and CatBoost ensemble tailored for the Alpha Radar Solana Sprint competition. This notebook focuses on maximising recall and F1 while keeping precision steady through extensive aggregation, directional statistics, and cross-validated threshold optimisation.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import gc\n",
    "import math\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import Dict, Iterable, List, Sequence, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from IPython.display import display\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    jaccard_score,\n",
    "    precision_recall_fscore_support,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.float_format\", lambda v: f\"{v:0.4f}\")\n",
    "np.random.seed(2025)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "BASE_DIR = Path.cwd()\n",
    "DATA_DIR = BASE_DIR / \"Dataset\" / \"alpha-radar-solana-sprint\"\n",
    "TARGET_PATH = BASE_DIR / \"Dataset\" / \"target_tokens.csv\"\n",
    "TRAIN_FILENAME = \"Sample_Dataset.csv\"\n",
    "EVALUATION_PATTERN = \"evaluation_set_30s_chunk_*.csv\"\n",
    "OUTPUT_DIR = BASE_DIR / \"outputs\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "EXPECTED_EVAL_ROWS = 64208\n",
    "SEEDS: Tuple[int, ...] = (42, 2025, 31415)\n",
    "N_FOLDS = 7\n",
    "\n",
    "AGG_NUMERIC_FUNCS = [\"mean\", \"std\", \"min\", \"max\", \"sum\", \"median\", \"last\"]\n",
    "QUANTILE_LEVELS = (0.10, 0.25, 0.50, 0.75, 0.90)\n",
    "EARLY_EVENT_WINDOWS: Tuple[int, ...] = (3, 5, 10, 20)\n",
    "EARLY_TIME_WINDOWS: Tuple[int, ...] = (5, 10, 15, 20, 25, 30)\n",
    "THRESHOLD_GRID = np.round(np.linspace(0.05, 0.995, 40), 3)\n",
    "\n",
    "NUMERIC_FILL_VALUE = 0.0\n",
    "NON_NUMERIC_COLUMNS = {\"timestamp\", \"mint_token_id\", \"holder\", \"trade_mode\", \"creator\", \"event_type\"}\n",
    "CATEGORICAL_TOP_K = 15\n",
    "\n",
    "if not DATA_DIR.exists():\n",
    "    raise FileNotFoundError(f\"Expected data directory at {DATA_DIR}\")\n",
    "train_path = DATA_DIR / TRAIN_FILENAME\n",
    "if not train_path.exists():\n",
    "    raise FileNotFoundError(f\"Training CSV missing at {train_path}\")\n",
    "if not TARGET_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Target token file missing at {TARGET_PATH}\")\n",
    "\n",
    "print(f\"Using data directory: {DATA_DIR}\")\n",
    "print(f\"Training CSV: {train_path}\")\n",
    "print(f\"Target token path: {TARGET_PATH}\")\n",
    "print(f\"Outputs will be written to: {OUTPUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def parse_timestamp_series(series: pd.Series) -> pd.Series:\n",
    "    parts = series.astype(str).str.split(':', n=1, expand=True)\n",
    "    minutes = pd.to_numeric(parts[0], errors='coerce')\n",
    "    seconds = pd.to_numeric(parts[1], errors='coerce')\n",
    "    return (minutes * 60 + seconds).astype('float32')\n",
    "\n",
    "\n",
    "def load_event_data(csv_path: Path) -> pd.DataFrame:\n",
    "    df = pd.read_csv(csv_path, low_memory=False)\n",
    "    if 'index' in df.columns:\n",
    "        df = df.drop(columns=['index'])\n",
    "    df['mint_token_id'] = df['mint_token_id'].astype(str)\n",
    "    if 'timestamp_seconds' not in df.columns and 'timestamp' in df.columns:\n",
    "        df['timestamp_seconds'] = parse_timestamp_series(df['timestamp'])\n",
    "    numeric_candidates = [c for c in df.columns if c not in NON_NUMERIC_COLUMNS]\n",
    "    for col in numeric_candidates:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    df[numeric_candidates] = df[numeric_candidates].astype('float32')\n",
    "    return df\n",
    "\n",
    "\n",
    "def aggregate_numeric(grouped: pd.core.groupby.generic.DataFrameGroupBy, numeric_cols: List[str]) -> pd.DataFrame:\n",
    "    if not numeric_cols:\n",
    "        return pd.DataFrame(index=grouped.size().index)\n",
    "    agg = grouped[numeric_cols].agg(AGG_NUMERIC_FUNCS)\n",
    "    agg.columns = [f\"{col}_{stat}\" for col, stat in agg.columns]\n",
    "    return agg\n",
    "\n",
    "\n",
    "def compute_quantiles(grouped: pd.core.groupby.generic.DataFrameGroupBy, numeric_cols: List[str]) -> pd.DataFrame:\n",
    "    frames = []\n",
    "    for q in QUANTILE_LEVELS:\n",
    "        quant = grouped[numeric_cols].quantile(q)\n",
    "        quant.columns = [f\"{col}_q{int(q*100):02d}\" for col in quant.columns]\n",
    "        frames.append(quant)\n",
    "    if frames:\n",
    "        return pd.concat(frames, axis=1)\n",
    "    return pd.DataFrame(index=grouped.size().index)\n",
    "\n",
    "\n",
    "def pivot_categorical(grouped: pd.core.groupby.generic.DataFrameGroupBy, cat_cols: Sequence[str], prefix: str) -> pd.DataFrame:\n",
    "    pivots: List[pd.DataFrame] = []\n",
    "    for col in cat_cols:\n",
    "        counts = grouped[col].value_counts(normalize=False).unstack(fill_value=0)\n",
    "        counts.columns = [f\"{prefix}{col}_{str(c)}_count\" for c in counts.columns]\n",
    "        ratios = counts.div(counts.sum(axis=1).replace(0, np.nan), axis=0)\n",
    "        ratios = ratios.add_suffix('_ratio').fillna(0)\n",
    "        pivots.extend([counts, ratios])\n",
    "    if pivots:\n",
    "        out = pd.concat(pivots, axis=1)\n",
    "        out.columns = pd.Index(out.columns).map(str)\n",
    "        return out\n",
    "    return pd.DataFrame(index=grouped.size().index)\n",
    "\n",
    "\n",
    "def derive_first_n_features(ordered: pd.DataFrame, n: int, numeric_cols: Sequence[str]) -> pd.DataFrame:\n",
    "    if ordered.empty:\n",
    "        return pd.DataFrame()\n",
    "    first_n = ordered.groupby('mint_token_id', sort=False).head(n)\n",
    "    frames: List[pd.DataFrame] = []\n",
    "    if 'timestamp_seconds' in first_n.columns:\n",
    "        timing = first_n.groupby('mint_token_id')['timestamp_seconds'].agg(['min', 'max', 'mean']).rename(columns={\n",
    "            'min': f'first{n}_time_min',\n",
    "            'max': f'first{n}_time_max',\n",
    "            'mean': f'first{n}_time_mean'\n",
    "        })\n",
    "        frames.append(timing)\n",
    "    if numeric_cols:\n",
    "        agg = first_n.groupby('mint_token_id')[list(numeric_cols)].agg(['mean', 'max', 'min']).astype('float32')\n",
    "        agg.columns = [f'first{n}_{col}_{stat}' for col, stat in agg.columns]\n",
    "        frames.append(agg)\n",
    "    if frames:\n",
    "        return pd.concat(frames, axis=1)\n",
    "    return pd.DataFrame(index=ordered['mint_token_id'].drop_duplicates())\n",
    "\n",
    "\n",
    "def compute_signed_aggregates(ordered: pd.DataFrame, numeric_cols: Sequence[str]) -> pd.DataFrame:\n",
    "    frames: List[pd.DataFrame] = []\n",
    "    for col in numeric_cols:\n",
    "        if not pd.api.types.is_numeric_dtype(ordered[col]):\n",
    "            continue\n",
    "        subset = ordered[['mint_token_id', col]].dropna()\n",
    "        if subset.empty:\n",
    "            continue\n",
    "        pos = subset[subset[col] > 0]\n",
    "        neg = subset[subset[col] < 0]\n",
    "        for label, part in (('pos', pos), ('neg', neg)):\n",
    "            if part.empty:\n",
    "                continue\n",
    "            grouped = part.groupby('mint_token_id')[col]\n",
    "            agg = grouped.agg(['sum', 'mean', 'max', 'min', 'count']).astype('float32')\n",
    "            agg.columns = [f'{col}_{label}_{stat}' for stat in agg.columns]\n",
    "            frames.append(agg)\n",
    "    if frames:\n",
    "        return pd.concat(frames, axis=1)\n",
    "    return pd.DataFrame(index=ordered['mint_token_id'].drop_duplicates())\n",
    "\n",
    "\n",
    "def compute_time_window_features(ordered: pd.DataFrame, numeric_cols: Sequence[str]) -> pd.DataFrame:\n",
    "    if 'relative_time' not in ordered.columns:\n",
    "        return pd.DataFrame(index=ordered['mint_token_id'].drop_duplicates())\n",
    "    frames: List[pd.DataFrame] = []\n",
    "    for window in EARLY_TIME_WINDOWS:\n",
    "        window_mask = ordered['relative_time'] <= window\n",
    "        window_events = ordered[window_mask]\n",
    "        if window_events.empty:\n",
    "            continue\n",
    "        grouped = window_events.groupby('mint_token_id', sort=False)\n",
    "        counts = grouped.size().rename(f'time_window_{window}_event_count')\n",
    "        frames.append(counts.to_frame())\n",
    "        usable_cols = [c for c in numeric_cols if c in window_events.columns]\n",
    "        if usable_cols:\n",
    "            agg = grouped[usable_cols].agg(['sum', 'mean', 'max']).astype('float32')\n",
    "            agg.columns = [f'time_window_{window}_{col}_{stat}' for col, stat in agg.columns]\n",
    "            frames.append(agg)\n",
    "    if frames:\n",
    "        return pd.concat(frames, axis=1)\n",
    "    return pd.DataFrame(index=ordered['mint_token_id'].drop_duplicates())\n",
    "\n",
    "\n",
    "def add_ratio_features(features: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = features.copy()\n",
    "    if 'event_count' in out.columns:\n",
    "        denom = out['event_count'].replace(0, np.nan)\n",
    "        if 'cat_trade_mode_buy_count' in out.columns:\n",
    "            out['buy_event_rate'] = out['cat_trade_mode_buy_count'] / denom\n",
    "        if 'cat_trade_mode_sell_count' in out.columns:\n",
    "            out['sell_event_rate'] = out['cat_trade_mode_sell_count'] / denom\n",
    "        if {'cat_trade_mode_buy_count', 'cat_trade_mode_sell_count'} <= set(out.columns):\n",
    "            out['buy_to_sell_ratio'] = out['cat_trade_mode_buy_count'] / out['cat_trade_mode_sell_count'].replace(0, np.nan)\n",
    "    if {'lifetime_seconds', 'event_count'} <= set(out.columns):\n",
    "        out['event_rate_per_second'] = out['event_count'] / out['lifetime_seconds'].replace(0, np.nan)\n",
    "    for prefix in ['sol_volume', 'token_volume', 'price', 'market_cap']:\n",
    "        max_col = f'{prefix}_max'\n",
    "        min_col = f'{prefix}_min'\n",
    "        if {max_col, min_col} <= set(out.columns):\n",
    "            out[f'{prefix}_range'] = out[max_col] - out[min_col]\n",
    "    if {'unique_holders', 'event_count'} <= set(out.columns):\n",
    "        out['holders_per_event'] = out['unique_holders'] / out['event_count'].replace(0, np.nan)\n",
    "    if {'unique_creators', 'event_count'} <= set(out.columns):\n",
    "        out['creators_per_event'] = out['unique_creators'] / out['event_count'].replace(0, np.nan)\n",
    "    out = out.replace([np.inf, -np.inf], NUMERIC_FILL_VALUE)\n",
    "    return out\n",
    "\n",
    "\n",
    "def finalise_features(features: pd.DataFrame) -> pd.DataFrame:\n",
    "    features = features.replace([np.inf, -np.inf], NUMERIC_FILL_VALUE).fillna(NUMERIC_FILL_VALUE)\n",
    "    for col in features.columns:\n",
    "        if features[col].dtype == 'float64':\n",
    "            features[col] = features[col].astype('float32')\n",
    "        elif features[col].dtype == 'int64':\n",
    "            features[col] = features[col].astype('int32')\n",
    "    features.index = features.index.astype(str)\n",
    "    return features\n",
    "\n",
    "\n",
    "def build_features(events: pd.DataFrame) -> pd.DataFrame:\n",
    "    if events.empty:\n",
    "        return pd.DataFrame()\n",
    "    events = events.copy()\n",
    "    events['mint_token_id'] = events['mint_token_id'].astype(str)\n",
    "    if 'timestamp_seconds' not in events.columns and 'timestamp' in events.columns:\n",
    "        events['timestamp_seconds'] = parse_timestamp_series(events['timestamp'])\n",
    "    ordered = events.sort_values(['mint_token_id', 'timestamp_seconds'], kind='mergesort')\n",
    "    if 'timestamp_seconds' in ordered.columns:\n",
    "        first_time = ordered.groupby('mint_token_id')['timestamp_seconds'].transform('min')\n",
    "        ordered['relative_time'] = ordered['timestamp_seconds'] - first_time\n",
    "        ordered['delta_time'] = ordered.groupby('mint_token_id')['timestamp_seconds'].diff().fillna(0)\n",
    "    grouped = ordered.groupby('mint_token_id', sort=False)\n",
    "\n",
    "    numeric_cols = [\n",
    "        col for col in ordered.columns\n",
    "        if col not in {'mint_token_id'} and pd.api.types.is_numeric_dtype(ordered[col])\n",
    "    ]\n",
    "    categorical_cols = [\n",
    "        col for col in ordered.columns\n",
    "        if ordered[col].dtype == 'object' and col not in {'mint_token_id'}\n",
    "    ]\n",
    "\n",
    "    base = pd.DataFrame(index=grouped.size().index)\n",
    "    base['event_count'] = grouped.size().astype('int32')\n",
    "    if 'timestamp_seconds' in ordered.columns:\n",
    "        base['lifetime_seconds'] = (grouped['timestamp_seconds'].max() - grouped['timestamp_seconds'].min()).fillna(0)\n",
    "        base['time_to_first_event'] = grouped['timestamp_seconds'].min().fillna(0)\n",
    "    if 'relative_time' in ordered.columns:\n",
    "        base['relative_time_max'] = grouped['relative_time'].max().fillna(0)\n",
    "    if 'delta_time' in ordered.columns:\n",
    "        base['delta_time_mean'] = grouped['delta_time'].mean().fillna(0)\n",
    "        base['delta_time_std'] = grouped['delta_time'].std().fillna(0)\n",
    "    if 'holder' in ordered.columns:\n",
    "        base['unique_holders'] = grouped['holder'].nunique(dropna=True)\n",
    "    if 'creator' in ordered.columns:\n",
    "        base['unique_creators'] = grouped['creator'].nunique(dropna=True)\n",
    "\n",
    "    numeric_summary = aggregate_numeric(grouped, numeric_cols)\n",
    "    quantile_summary = compute_quantiles(grouped, numeric_cols)\n",
    "\n",
    "    capped_events = ordered.copy()\n",
    "    cat_frames: List[pd.DataFrame] = []\n",
    "    if categorical_cols:\n",
    "        for col in categorical_cols:\n",
    "            top_values = capped_events[col].value_counts().head(CATEGORICAL_TOP_K).index\n",
    "            capped_events[col] = capped_events[col].where(capped_events[col].isin(top_values), other='__OTHER__')\n",
    "        capped_grouped = capped_events.groupby('mint_token_id', sort=False)\n",
    "        cat_frames.append(pivot_categorical(capped_grouped, categorical_cols, prefix='cat_'))\n",
    "\n",
    "    first_n_frames = [derive_first_n_features(ordered, n, numeric_cols) for n in EARLY_EVENT_WINDOWS]\n",
    "    signed_frames = compute_signed_aggregates(ordered, numeric_cols)\n",
    "    time_window_frames = compute_time_window_features(ordered, [c for c in numeric_cols if c not in {'relative_time', 'delta_time'}])\n",
    "\n",
    "    features = pd.concat([\n",
    "        base,\n",
    "        numeric_summary,\n",
    "        quantile_summary,\n",
    "        *cat_frames,\n",
    "        *first_n_frames,\n",
    "        signed_frames,\n",
    "        time_window_frames,\n",
    "    ], axis=1)\n",
    "\n",
    "    features = add_ratio_features(features)\n",
    "    features = finalise_features(features)\n",
    "    features = features.sort_index()\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def evaluate_thresholds(y_true: pd.Series, y_prob: np.ndarray, thresholds: Iterable[float]) -> pd.DataFrame:\n",
    "    records = []\n",
    "    for thr in thresholds:\n",
    "        y_pred = (y_prob >= thr).astype(int)\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "            y_true, y_pred, average='binary', zero_division=0\n",
    "        )\n",
    "        try:\n",
    "            jac = jaccard_score(y_true, y_pred)\n",
    "        except ValueError:\n",
    "            jac = 0.0\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "        records.append({\n",
    "            'threshold': float(thr),\n",
    "            'accuracy': acc,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1,\n",
    "            'jaccard': jac,\n",
    "            'tp': int(tp),\n",
    "            'fp': int(fp),\n",
    "            'fn': int(fn),\n",
    "            'tn': int(tn),\n",
    "        })\n",
    "    return pd.DataFrame.from_records(records)\n",
    "\n",
    "\n",
    "def select_best_threshold(metrics: pd.DataFrame, min_recall: float = 0.88) -> pd.Series:\n",
    "    if metrics.empty:\n",
    "        raise ValueError('No threshold metrics available.')\n",
    "    filtered = metrics[metrics['recall'] >= min_recall]\n",
    "    if filtered.empty:\n",
    "        filtered = metrics.copy()\n",
    "    ordered = filtered.sort_values(\n",
    "        ['f1', 'recall', 'precision', 'accuracy'],\n",
    "        ascending=[False, False, False, False]\n",
    "    )\n",
    "    return ordered.iloc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "sample_events = load_event_data(DATA_DIR / TRAIN_FILENAME)\n",
    "target_tokens = pd.read_csv(TARGET_PATH, header=None, names=['mint_token_id'])\n",
    "target_tokens['mint_token_id'] = target_tokens['mint_token_id'].astype(str)\n",
    "target_set = set(target_tokens['mint_token_id'])\n",
    "\n",
    "print(f'Sample events shape: {sample_events.shape}')\n",
    "print(f'Unique tokens in sample events: {sample_events['mint_token_id'].nunique()}')\n",
    "print(f'Target tokens provided: {len(target_set)}')\n",
    "\n",
    "train_features = build_features(sample_events)\n",
    "train_features['is_target'] = train_features.index.isin(target_set).astype('int8')\n",
    "\n",
    "print(f'Training feature matrix: {train_features.shape}')\n",
    "class_counts = train_features['is_target'].value_counts().rename('token_count')\n",
    "display(class_counts.to_frame())\n",
    "positive_rate = class_counts.get(1, 0) / class_counts.sum()\n",
    "print(f'Positive token rate: {positive_rate:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "feature_columns = [col for col in train_features.columns if col != 'is_target']\n",
    "X = train_features[feature_columns].astype('float32')\n",
    "y = train_features['is_target'].astype('int32')\n",
    "\n",
    "catboost_base_params = {\n",
    "    'depth': 8,\n",
    "    'learning_rate': 0.035,\n",
    "    'iterations': 4500,\n",
    "    'loss_function': 'Logloss',\n",
    "    'eval_metric': 'AUC',\n",
    "    'l2_leaf_reg': 10.0,\n",
    "    'bagging_temperature': 0.6,\n",
    "    'random_strength': 1.5,\n",
    "    'border_count': 128,\n",
    "    'auto_class_weights': 'Balanced',\n",
    "    'grow_policy': 'SymmetricTree',\n",
    "    'bootstrap_type': 'Bernoulli',\n",
    "    'subsample': 0.9,\n",
    "    'task_type': 'CPU',\n",
    "}\n",
    "\n",
    "print(f'Feature matrix shape: {X.shape}')\n",
    "print(f'Using {len(feature_columns)} engineered features')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "oof_prob = np.zeros(len(X), dtype='float32')\n",
    "oof_counts = np.zeros(len(X), dtype='int32')\n",
    "feature_importance_accumulator = np.zeros(len(feature_columns), dtype='float64')\n",
    "fold_records: List[Dict] = []\n",
    "models: List[CatBoostClassifier] = []\n",
    "thresholds: List[float] = []\n",
    "\n",
    "for seed in SEEDS:\n",
    "    skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=seed)\n",
    "    for fold_idx, (train_idx, valid_idx) in enumerate(skf.split(X, y), start=1):\n",
    "        params = dict(catboost_base_params)\n",
    "        params['random_seed'] = seed + fold_idx\n",
    "\n",
    "        X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "        y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "\n",
    "        train_pool = Pool(X_train, label=y_train)\n",
    "        valid_pool = Pool(X_valid, label=y_valid)\n",
    "\n",
    "        model = CatBoostClassifier(**params)\n",
    "        model.fit(\n",
    "            train_pool,\n",
    "            eval_set=valid_pool,\n",
    "            verbose=250,\n",
    "            use_best_model=True,\n",
    "            early_stopping_rounds=200,\n",
    "        )\n",
    "\n",
    "        fold_prob = model.predict_proba(valid_pool)[:, 1]\n",
    "        oof_prob[valid_idx] += fold_prob\n",
    "        oof_counts[valid_idx] += 1\n",
    "\n",
    "        metrics_df = evaluate_thresholds(y_valid, fold_prob, THRESHOLD_GRID)\n",
    "        best_row = select_best_threshold(metrics_df, min_recall=0.90)\n",
    "\n",
    "        fold_record = best_row.to_dict()\n",
    "        fold_record.update({\n",
    "            'seed': seed,\n",
    "            'fold': fold_idx,\n",
    "            'auc': roc_auc_score(y_valid, fold_prob),\n",
    "            'positive_rate': float(y_valid.mean()),\n",
    "            'best_iteration': model.get_best_iteration(),\n",
    "        })\n",
    "        fold_records.append(fold_record)\n",
    "        thresholds.append(float(best_row['threshold']))\n",
    "\n",
    "        feature_importance_accumulator += model.get_feature_importance(type='FeatureImportance')\n",
    "        models.append(model)\n",
    "\n",
    "        print(\n",
    "            f\"Seed {seed} Fold {fold_idx}: AUC={fold_record['auc']:.4f} F1={fold_record['f1']:.4f} \"\n",
    "            f\"Recall={fold_record['recall']:.4f} Thr={fold_record['threshold']:.3f}\"\n",
    "        )\n",
    "\n",
    "fold_summary_df = pd.DataFrame(fold_records)\n",
    "if not fold_summary_df.empty:\n",
    "    display(fold_summary_df.sort_values(['seed', 'fold']).reset_index(drop=True))\n",
    "\n",
    "aggregated_threshold = float(np.median(thresholds)) if thresholds else 0.5\n",
    "print(f'Median optimal threshold across folds: {aggregated_threshold:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "valid_mask = oof_counts > 0\n",
    "oof_prob[valid_mask] = oof_prob[valid_mask] / oof_counts[valid_mask]\n",
    "\n",
    "agg_pred = (oof_prob >= aggregated_threshold).astype(int)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y, agg_pred, average='binary', zero_division=0)\n",
    "accuracy = accuracy_score(y, agg_pred)\n",
    "jaccard = jaccard_score(y, agg_pred)\n",
    "auc = roc_auc_score(y, oof_prob)\n",
    "\n",
    "print(f'OOF metrics at aggregated threshold {aggregated_threshold:.4f}:')\n",
    "print(f'  Accuracy: {accuracy:.4f}')\n",
    "print(f'  Precision: {precision:.4f}')\n",
    "print(f'  Recall: {recall:.4f}')\n",
    "print(f'  F1-score: {f1:.4f}')\n",
    "print(f'  Jaccard: {jaccard:.4f}')\n",
    "print(f'  AUC: {auc:.4f}')\n",
    "\n",
    "conf_mtx = confusion_matrix(y, agg_pred)\n",
    "conf_df = pd.DataFrame(conf_mtx, index=['Actual 0', 'Actual 1'], columns=['Pred 0', 'Pred 1'])\n",
    "display(conf_df)\n",
    "\n",
    "print('Classification report:')\n",
    "print(classification_report(y, agg_pred, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "feature_importances = pd.Series(feature_importance_accumulator / max(1, len(models)), index=feature_columns)\n",
    "feature_importances = feature_importances.sort_values(ascending=False)\n",
    "display(feature_importances.head(40).to_frame(name='importance'))\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "final_models: List[CatBoostClassifier] = []\n",
    "for seed in SEEDS:\n",
    "    params = dict(catboost_base_params)\n",
    "    params['random_seed'] = seed\n",
    "    final_model = CatBoostClassifier(**params)\n",
    "    final_model.fit(Pool(X, label=y), verbose=250)\n",
    "    final_models.append(final_model)\n",
    "\n",
    "print(f'Trained {len(final_models)} final models for ensembling.')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluation_files = sorted(DATA_DIR.glob(EVALUATION_PATTERN))\n",
    "if not evaluation_files:\n",
    "    raise FileNotFoundError('No evaluation set chunks found. Check the dataset path and pattern.')\n",
    "\n",
    "print(f'Found {len(evaluation_files)} evaluation chunks.')\n",
    "\n",
    "eval_events = pd.concat([load_event_data(path) for path in evaluation_files], ignore_index=True)\n",
    "eval_events['mint_token_id'] = eval_events['mint_token_id'].astype(str)\n",
    "\n",
    "eval_features = build_features(eval_events)\n",
    "\n",
    "missing_cols = [col for col in feature_columns if col not in eval_features.columns]\n",
    "for col in missing_cols:\n",
    "    eval_features[col] = NUMERIC_FILL_VALUE\n",
    "\n",
    "eval_features = eval_features[feature_columns].astype('float32')\n",
    "\n",
    "eval_token_order = eval_events['mint_token_id'].drop_duplicates().astype(str).tolist()\n",
    "eval_features = eval_features.reindex(eval_token_order)\n",
    "missing_tokens = [tok for tok in eval_token_order if tok not in eval_features.index]\n",
    "if missing_tokens:\n",
    "    filler = pd.DataFrame(NUMERIC_FILL_VALUE, index=missing_tokens, columns=feature_columns)\n",
    "    eval_features = pd.concat([eval_features, filler])\n",
    "    eval_features = eval_features.reindex(eval_token_order)\n",
    "\n",
    "eval_features = eval_features.fillna(NUMERIC_FILL_VALUE)\n",
    "\n",
    "if len(eval_features) != EXPECTED_EVAL_ROWS:\n",
    "    raise ValueError(f'Expected {EXPECTED_EVAL_ROWS} evaluation rows, found {len(eval_features)}')\n",
    "\n",
    "print(f'Evaluation events shape: {eval_events.shape}')\n",
    "print(f'Evaluation feature matrix: {eval_features.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_pool = Pool(eval_features)\n",
    "model_probs = []\n",
    "for model in final_models:\n",
    "    model_probs.append(model.predict_proba(eval_pool)[:, 1])\n",
    "\n",
    "ensemble_prob = np.mean(model_probs, axis=0)\n",
    "ensemble_pred = (ensemble_prob >= aggregated_threshold).astype(int)\n",
    "\n",
    "detailed_df = pd.DataFrame({\n",
    "    'mint_token_id': eval_features.index,\n",
    "    'prediction_score': ensemble_prob,\n",
    "    'is_target': ensemble_pred,\n",
    "}).reset_index(drop=True)\n",
    "\n",
    "submission_df = detailed_df[['mint_token_id', 'is_target']]\n",
    "positive_df = detailed_df[detailed_df['is_target'] == 1].copy()\n",
    "positive_df['threshold_used'] = aggregated_threshold\n",
    "\n",
    "submission_path = OUTPUT_DIR / 'submission.csv'\n",
    "detailed_path = OUTPUT_DIR / 'detailed_predictions.csv'\n",
    "positive_path = OUTPUT_DIR / 'positive_predictions.csv'\n",
    "\n",
    "submission_df.to_csv(submission_path, index=False)\n",
    "detailed_df.to_csv(detailed_path, index=False)\n",
    "positive_df.to_csv(positive_path, index=False)\n",
    "\n",
    "print(f'Saved submission to {submission_path} (rows={len(submission_df)})')\n",
    "print(f'Saved detailed predictions to {detailed_path}')\n",
    "print(f'Saved positive predictions to {positive_path} (rows={len(positive_df)})')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(detailed_df.sort_values('prediction_score', ascending=False).head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Persist key artefacts for downstream analysis\n",
    "fold_summary_path = OUTPUT_DIR / 'cv_fold_summary.csv'\n",
    "feature_importances_path = OUTPUT_DIR / 'feature_importances.csv'\n",
    "\n",
    "if not fold_summary_df.empty:\n",
    "    fold_summary_df.to_csv(fold_summary_path, index=False)\n",
    "    print(f'Fold summary saved to {fold_summary_path}')\n",
    "\n",
    "feature_importances.to_csv(feature_importances_path, header=['importance'])\n",
    "print(f'Feature importances saved to {feature_importances_path}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}